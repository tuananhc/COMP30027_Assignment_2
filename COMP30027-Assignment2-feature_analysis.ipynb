{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The University of Melbourne, School of Computing and Information Systems\n",
    "# COMP30027 Machine Learning, 2022 Semester 1\n",
    "\n",
    "## Assignment 2: Sentiment Classification of Tweets\n",
    "\n",
    "This is a sample code to assist you with vectorising the 'Train' dataset for your assignment 2.\n",
    "\n",
    "First we read the CSV datafiles (Train and Test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>805582613687713000</td>\n",
       "      <td>doctors hit campaign trail as race to medical...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>637480203497832000</td>\n",
       "      <td>is anybody going to the radio station tomorro...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>641096279930507000</td>\n",
       "      <td>i just found out naruto didn't become the 5th...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>625730917647126000</td>\n",
       "      <td>\"prince george reservist who died saturday ju...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>633292370906230000</td>\n",
       "      <td>season in the sun versi nirvana rancak gak..s...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21797</th>\n",
       "      <td>27896</td>\n",
       "      <td>805677750363095000</td>\n",
       "      <td>@hrtablaze the beginning of a dictatorship is ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21798</th>\n",
       "      <td>27897</td>\n",
       "      <td>637854813930196000</td>\n",
       "      <td>son idc anymore. i'm going by shawn tomorrow</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21799</th>\n",
       "      <td>27898</td>\n",
       "      <td>802374277047656000</td>\n",
       "      <td>but remember the clinton foundation?? https://...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21800</th>\n",
       "      <td>27899</td>\n",
       "      <td>640441306494296000</td>\n",
       "      <td>press: \"r u worried murray dominated his 3rd r...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21801</th>\n",
       "      <td>27900</td>\n",
       "      <td>638666306015789000</td>\n",
       "      <td>@rinashah i have been using moto g 2nd gen for...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21802 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                  id  \\\n",
       "0               2  805582613687713000   \n",
       "1               3  637480203497832000   \n",
       "2               4  641096279930507000   \n",
       "3               5  625730917647126000   \n",
       "4               6  633292370906230000   \n",
       "...           ...                 ...   \n",
       "21797       27896  805677750363095000   \n",
       "21798       27897  637854813930196000   \n",
       "21799       27898  802374277047656000   \n",
       "21800       27899  640441306494296000   \n",
       "21801       27900  638666306015789000   \n",
       "\n",
       "                                                    text sentiment  \n",
       "0       doctors hit campaign trail as race to medical...   neutral  \n",
       "1       is anybody going to the radio station tomorro...  positive  \n",
       "2       i just found out naruto didn't become the 5th...   neutral  \n",
       "3       \"prince george reservist who died saturday ju...   neutral  \n",
       "4       season in the sun versi nirvana rancak gak..s...  positive  \n",
       "...                                                  ...       ...  \n",
       "21797  @hrtablaze the beginning of a dictatorship is ...  negative  \n",
       "21798       son idc anymore. i'm going by shawn tomorrow   neutral  \n",
       "21799  but remember the clinton foundation?? https://...   neutral  \n",
       "21800  press: \"r u worried murray dominated his 3rd r...   neutral  \n",
       "21801  @rinashah i have been using moto g 2nd gen for...  positive  \n",
       "\n",
       "[21802 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_recall_fscore_support\n",
    "from sklearn.utils import shuffle\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "\n",
    "train_data = pd.read_csv(\"Train.csv\", sep=',')\n",
    "test_data = pd.read_csv(\"Test.csv\", sep=',')\n",
    "\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/chautuananh/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/chautuananh/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/chautuananh/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/omw-1.4.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/chautuananh/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of data to download from nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we separate the tweet text and the label (sentiment). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train length: 21802\n",
      "Test length: 6099\n"
     ]
    }
   ],
   "source": [
    "#separating instance and label for Train\n",
    "X_train_raw = [x[0] for x in train_data[['text']].values]\n",
    "Y_train = [x[0] for x in train_data[['sentiment']].values]\n",
    "\n",
    "#check the result\n",
    "print(\"Train length:\",len(X_train_raw))\n",
    "\n",
    "#separating instance and label for Test\n",
    "X_test_raw = [x[0] for x in test_data[['text']].values]\n",
    "\n",
    "#check the result\n",
    "print(\"Test length:\",len(X_test_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " is anybody going to the radio station tomorrow to see shawn? me and my friend may go but we would like to make new friends/meet there (:\t\n"
     ]
    }
   ],
   "source": [
    "#Let's see one example tweet\n",
    "print(X_train_raw[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Bag of Words (BoW)\n",
    "In this approach, we use the **CountVectorizer** library to separate all the words in the Train corpus (dataset). These words are then used as the 'vectors' or 'features' to represent each instance (Tweet) in `Train` and `Test` datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train feature space size (using BoW): (21802, 44045)\n",
      "Test feature space size (using BoW): (6099, 44045)\n"
     ]
    }
   ],
   "source": [
    "BoW_vectorizer = CountVectorizer()\n",
    "\n",
    "#Build the feature set (vocabulary) and vectorise the Tarin dataset using BoW\n",
    "X_train_BoW = BoW_vectorizer.fit_transform(X_train_raw)\n",
    "\n",
    "#Use the feature set (vocabulary) from Train to vectorise the Test dataset \n",
    "X_test_BoW = BoW_vectorizer.transform(X_test_raw)\n",
    "\n",
    "print(\"Train feature space size (using BoW):\",X_train_BoW.shape)\n",
    "print(\"Test feature space size (using BoW):\",X_test_BoW.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now each row is a list of tuples with the vector_id (word_id in the vocabulary) and the number of times it repeated in that given instance (tweet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 38395)\t3\n",
      "  (0, 19715)\t1\n",
      "  (0, 3989)\t1\n",
      "  (0, 16331)\t1\n",
      "  (0, 37689)\t1\n",
      "  (0, 31309)\t1\n",
      "  (0, 36044)\t1\n",
      "  (0, 38468)\t1\n",
      "  (0, 34040)\t1\n",
      "  (0, 34418)\t1\n",
      "  (0, 24586)\t1\n",
      "  (0, 3761)\t1\n",
      "  (0, 26105)\t1\n",
      "  (0, 15223)\t1\n",
      "  (0, 24454)\t1\n",
      "  (0, 16261)\t1\n",
      "  (0, 7246)\t1\n",
      "  (0, 41365)\t1\n",
      "  (0, 42083)\t1\n",
      "  (0, 22991)\t1\n",
      "  (0, 23985)\t1\n",
      "  (0, 26660)\t1\n",
      "  (0, 15226)\t1\n",
      "  (0, 24659)\t1\n",
      "  (0, 37883)\t1\n"
     ]
    }
   ],
   "source": [
    "#Let's see one example tweet using the BoW feature space\n",
    "print(X_train_BoW[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can save the created vocabulary for the given dataset in a separate file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict = BoW_vectorizer.vocabulary_\n",
    "output_pd = pd.DataFrame(list(output_dict.items()),columns = ['word','count'])\n",
    "\n",
    "output_pd.T.to_csv('BoW-vocab.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. TFIDF\n",
    "In this approach, we use the **TfidfVectorizer** library to separate all the words in this corpus (dataset). Same as the BoW approach, these words are then used as the 'vectors' or 'features' to represent each instance (Tweet).\n",
    "\n",
    "However, in this method for each instance the value associated with each 'vector' (word) is not the number of times the word repeated in that tweet, but the TFIDF value of then 'voctor' (word)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train feature space size (using TFIDF): (21802, 44045)\n",
      "Test feature space size (using TFIDF): (6099, 44045)\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Build the feature set (vocabulary) and vectorise the Train dataset using TFIDF\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train_raw)\n",
    "\n",
    "# Use the feature set (vocabulary) from Train to vectorise the Test dataset \n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test_raw)\n",
    "\n",
    "print(\"Train feature space size (using TFIDF):\",X_train_tfidf.shape)\n",
    "print(\"Test feature space size (using TFIDF):\",X_test_tfidf.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 37883)\t0.18565385954834512\n",
      "  (0, 24659)\t0.2500345232367134\n",
      "  (0, 15226)\t0.25639046572035723\n",
      "  (0, 26660)\t0.17561152736960378\n",
      "  (0, 23985)\t0.1925927500306722\n",
      "  (0, 22991)\t0.16044767939535962\n",
      "  (0, 42083)\t0.18984640176982912\n",
      "  (0, 41365)\t0.1543207744837252\n",
      "  (0, 7246)\t0.14059126992943502\n",
      "  (0, 16261)\t0.1784628628725588\n",
      "  (0, 24454)\t0.12804387104621462\n",
      "  (0, 15223)\t0.26344567340807307\n",
      "  (0, 26105)\t0.14662061838154353\n",
      "  (0, 3761)\t0.09883064069307852\n",
      "  (0, 24586)\t0.1579972519146742\n",
      "  (0, 34418)\t0.22806178452645745\n",
      "  (0, 34040)\t0.1638445966736955\n",
      "  (0, 38468)\t0.13527781692615354\n",
      "  (0, 36044)\t0.34058106427217183\n",
      "  (0, 31309)\t0.2838666463265357\n",
      "  (0, 37689)\t0.06611242944726782\n",
      "  (0, 16331)\t0.16788221772423795\n",
      "  (0, 3989)\t0.29703234834833714\n",
      "  (0, 19715)\t0.1065038202170494\n",
      "  (0, 38395)\t0.2534685554135372\n"
     ]
    }
   ],
   "source": [
    "#Let's see one example tweet using the TFIDF feature space\n",
    "print(X_train_tfidf[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our baseline evaluation, which is a Zero-R baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Counter.most_common of Counter({'neutral': 12659, 'positive': 5428, 'negative': 3715})>\n"
     ]
    }
   ],
   "source": [
    "# Use ZeroR as our baseline\n",
    "def baseline(train_data, test_data):\n",
    "    frequencies = Counter(train_data).most_common(1)[0][0]\n",
    "    print(Counter(train_data).most_common)\n",
    "    return [frequencies] * len(test_data)\n",
    "\n",
    "sentiments = pd.DataFrame({\n",
    "  \"id\": [x[0] for x in test_data[['id']].values],\n",
    "  \"sentiment\": baseline(Y_train, X_test_raw)\n",
    "})\n",
    "sentiments.to_csv(\"zeror.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess function\n",
    "\n",
    "negation_dict = {\n",
    "    \"don't\": \"do not\",\n",
    "    \"can't\": \"can not\",\n",
    "    \"couldn't\": \"could not\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"haven't\": \"have not\",\n",
    "    \"hadn't\": \"had not\",\n",
    "    \"isn't\": \"is not\",\n",
    "    \"aren't\": \"are not\",\n",
    "    \"ain't\": \"am not\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"wouldn't\": \"would not\",\n",
    "    \"shouldn't\": \"should not\",\n",
    "    \"mustn't\": \"must not\",\n",
    "    \"wasn't\": \"was not\",\n",
    "    \"weren't\": \"were not\",\n",
    "}\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "ps = PorterStemmer()\n",
    "stop_words = stopwords.words(\"english\")\n",
    "stop_words.append(\"may\")\n",
    "\n",
    "tag_dict = defaultdict(lambda: wordnet.NOUN)\n",
    "tag_dict['J'] = wordnet.ADJ\n",
    "tag_dict['V'] = wordnet.VERB\n",
    "tag_dict['R'] = wordnet.ADV\n",
    "\n",
    "def preprocess(data):\n",
    "    result = []\n",
    "    for instance in data:\n",
    "        instance = instance.lower()\n",
    "\n",
    "        # Remove usernames and hyperlinks\n",
    "        instance = re.sub(r\"@\\S*|https?://\\S*|\\d\", \"\", instance)\n",
    "        \n",
    "        # Remove whitespaces\n",
    "        instance = re.sub(r\"\\s\\s+\", \" \", instance)\n",
    "\n",
    "        instance = instance.split()\n",
    "\n",
    "        for j in range(len(instance)):\n",
    "            # Negation handling\n",
    "            if instance[j] in negation_dict:\n",
    "                instance[j] = negation_dict[instance[j]]\n",
    "\n",
    "            # Remove special character\n",
    "            instance[j] = re.sub(r\"[^\\sa-zA-Z0-9]+\", \" \", instance[j])\n",
    "\n",
    "            # Normalize characters - convert characters that appear 3 or more times consecutively to a single character\n",
    "            instance[j] = re.sub(r'([a-z])\\1{2,}', r'\\1', instance[j])\n",
    "\n",
    "        # Remove stop words\n",
    "        instance = list(filter(lambda x: x not in stop_words or x == \"not\", instance))\n",
    "        # Lemmatize the words\n",
    "        tags = pos_tag(instance)\n",
    "        instance = list(map(lambda item: lemmatizer.lemmatize(item[0], tag_dict[item[1][0]]), tags))\n",
    "\n",
    "        instance = \" \".join(instance)\n",
    "\n",
    "        # if instance:\n",
    "        result.append(instance)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove neutral instances to avoid biased in training\n",
    "neutrals = train_data[train_data['sentiment'] == \"neutral\"]\n",
    "neutrals = neutrals.sample(frac=0.5, random_state=1)\n",
    "positives = train_data[train_data['sentiment'] == \"positive\"]\n",
    "negatives = train_data[train_data['sentiment'] == \"negative\"]\n",
    "\n",
    "# Patch together\n",
    "unbiased_dataset = neutrals.append(positives, ignore_index=True)\n",
    "unbiased_dataset = unbiased_dataset.append(negatives, ignore_index=True)\n",
    "unbiased_dataset = unbiased_dataset.sample(frac=1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>0.649</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>0.720</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>0.497</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          precision  recall  f1-score\n",
       "positive      0.649   0.590     0.618\n",
       "negative      0.720   0.200     0.312\n",
       "neutral       0.497   0.745     0.596"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform 10 fold cross-validation on MNB\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "\n",
    "kf = KFold(n_splits=10)\n",
    "kf.get_n_splits(unbiased_dataset)\n",
    "\n",
    "accuracies_MNB = []\n",
    "positive_MNB = defaultdict(list)\n",
    "negative_MNB = defaultdict(list)\n",
    "neutral_MNB = defaultdict(list)\n",
    "\n",
    "for train_index, test_index in kf.split(unbiased_dataset):\n",
    "    train = unbiased_dataset.iloc[train_index]\n",
    "    test = unbiased_dataset.iloc[test_index]\n",
    "    X_train = [x[0] for x in train[['text']].values]\n",
    "    Y_train = [x[0] for x in train[['sentiment']].values]\n",
    "    X_test = [x[0] for x in test[['text']].values]\n",
    "    Y_test = [x[0] for x in test[['sentiment']].values]\n",
    "    \n",
    "    # Preprocess the data\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    processed_data = preprocess(X_train)\n",
    "    processed_data_tf_idf = tfidf_vectorizer.fit_transform(processed_data)\n",
    "    processed_test_data_tf_idf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "    mnb.fit(processed_data_tf_idf, Y_train)\n",
    "    prediction = mnb.predict(processed_test_data_tf_idf)\n",
    "    result = precision_recall_fscore_support(Y_test, prediction, average=None, labels=['positive', 'neutral', 'negative'])\n",
    "    positive_MNB[\"precision\"].append(result[0][0])\n",
    "    neutral_MNB[\"precision\"].append(result[0][1])\n",
    "    negative_MNB[\"precision\"].append(result[0][2])\n",
    "    positive_MNB[\"recall\"].append(result[1][0])\n",
    "    neutral_MNB[\"recall\"].append(result[1][1])\n",
    "    negative_MNB[\"recall\"].append(result[1][2])\n",
    "    positive_MNB[\"f1-score\"].append(result[2][0])\n",
    "    neutral_MNB[\"f1-score\"].append(result[2][1])\n",
    "    negative_MNB[\"f1-score\"].append(result[2][2])\n",
    "    \n",
    "    accuracy = accuracy_score(Y_test, prediction)\n",
    "    accuracies_MNB.append(accuracy)    \n",
    "    \n",
    "\n",
    "for key in positive_MNB:\n",
    "    positive_MNB[key] = np.mean(positive_MNB[key])\n",
    "    negative_MNB[key] = np.mean(negative_MNB[key])\n",
    "    neutral_MNB[key] = np.mean(neutral_MNB[key])\n",
    "\n",
    "df_MNB = pd.DataFrame([positive_MNB, negative_MNB, neutral_MNB], index=[\"positive\", \"negative\", \"neutral\"])\n",
    "df_MNB.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>0.647</td>\n",
       "      <td>0.579</td>\n",
       "      <td>0.610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>0.735</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neutral</th>\n",
       "      <td>0.494</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          precision  recall  f1-score\n",
       "Positive      0.647   0.579     0.610\n",
       "Negative      0.735   0.179     0.286\n",
       "Neutral       0.494   0.755     0.597"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3-fold MNB\n",
    "\n",
    "mnb_3 = MultinomialNB()\n",
    "\n",
    "# Perform 10 fold cross-validation\n",
    "kf = KFold(n_splits=3)\n",
    "kf.get_n_splits(unbiased_dataset)\n",
    "\n",
    "accuracies_3 = []\n",
    "positive_MNB_3 = defaultdict(list)\n",
    "negative_MNB_3 = defaultdict(list)\n",
    "neutral_MNB_3 = defaultdict(list)\n",
    "\n",
    "for train_index, test_index in kf.split(unbiased_dataset):\n",
    "    train = unbiased_dataset.iloc[train_index]\n",
    "    test = unbiased_dataset.iloc[test_index]\n",
    "    X_train = [x[0] for x in train[['text']].values]\n",
    "    Y_train = [x[0] for x in train[['sentiment']].values]\n",
    "    X_test = [x[0] for x in test[['text']].values]\n",
    "    Y_test = [x[0] for x in test[['sentiment']].values]\n",
    "\n",
    "    # Preprocess the data\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    processed_data = preprocess(X_train)\n",
    "    processed_data_tf_idf = tfidf_vectorizer.fit_transform(processed_data)\n",
    "    processed_test_data_tf_idf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "    mnb_3.fit(processed_data_tf_idf, Y_train)\n",
    "    prediction = mnb_3.predict(processed_test_data_tf_idf)\n",
    "    result = precision_recall_fscore_support(Y_test, prediction, average=None, labels=['positive', 'neutral', 'negative'])\n",
    "    positive_MNB_3[\"precision\"].append(result[0][0])\n",
    "    neutral_MNB_3[\"precision\"].append(result[0][1])\n",
    "    negative_MNB_3[\"precision\"].append(result[0][2])\n",
    "    positive_MNB_3[\"recall\"].append(result[1][0])\n",
    "    neutral_MNB_3[\"recall\"].append(result[1][1])\n",
    "    negative_MNB_3[\"recall\"].append(result[1][2])\n",
    "    positive_MNB_3[\"f1-score\"].append(result[2][0])\n",
    "    neutral_MNB_3[\"f1-score\"].append(result[2][1])\n",
    "    negative_MNB_3[\"f1-score\"].append(result[2][2])\n",
    "    \n",
    "    accuracy = accuracy_score(Y_test, prediction)\n",
    "    accuracies_3.append(accuracy)    \n",
    "\n",
    "for key in positive_MNB_3:\n",
    "    positive_MNB_3[key] = np.mean(positive_MNB_3[key])\n",
    "    negative_MNB_3[key] = np.mean(negative_MNB_3[key])\n",
    "    neutral_MNB_3[key] = np.mean(neutral_MNB_3[key])\n",
    "\n",
    "df_MNB_3 = pd.DataFrame([positive_MNB_3, negative_MNB_3, neutral_MNB_3], index=[\"Positive\", \"Negative\", \"Neutral\"])\n",
    "df_MNB_3.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>0.828</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>0.333</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>0.587</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          precision  recall  f1-score\n",
       "positive      0.828   0.049     0.092\n",
       "negative      0.333   0.001     0.002\n",
       "neutral       0.587   0.995     0.736"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ================== MNB ON RAW DATA ==================\n",
    "\n",
    "mnb_raw = MultinomialNB()\n",
    "\n",
    "# Perform 10 fold cross-validation\n",
    "kf = KFold(n_splits=10)\n",
    "kf.get_n_splits(train_data)\n",
    "\n",
    "accuracies_MNB_raw = []\n",
    "positive_MNB_raw = defaultdict(list)\n",
    "negative_MNB_raw = defaultdict(list)\n",
    "neutral_MNB_raw = defaultdict(list)\n",
    "\n",
    "for train_index, test_index in kf.split(train_data):\n",
    "    train = train_data.iloc[train_index]\n",
    "    test = train_data.iloc[test_index]\n",
    "    X_train = [x[0] for x in train[['text']].values]\n",
    "    Y_train = [x[0] for x in train[['sentiment']].values]\n",
    "    X_test = [x[0] for x in test[['text']].values]\n",
    "    Y_test = [x[0] for x in test[['sentiment']].values]\n",
    "\n",
    "    # Preprocess the data\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    train_data_tf_idf = tfidf_vectorizer.fit_transform(X_train)\n",
    "    test_data_tf_idf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "    mnb_raw.fit(train_data_tf_idf, Y_train)\n",
    "    prediction = mnb_raw.predict(test_data_tf_idf)\n",
    "    result = precision_recall_fscore_support(Y_test, prediction, average=None, labels=['positive', 'neutral', 'negative'])\n",
    "    positive_MNB_raw[\"precision\"].append(result[0][0])\n",
    "    neutral_MNB_raw[\"precision\"].append(result[0][1])\n",
    "    negative_MNB_raw[\"precision\"].append(result[0][2])\n",
    "    positive_MNB_raw[\"recall\"].append(result[1][0])\n",
    "    neutral_MNB_raw[\"recall\"].append(result[1][1])\n",
    "    negative_MNB_raw[\"recall\"].append(result[1][2])\n",
    "    positive_MNB_raw[\"f1-score\"].append(result[2][0])\n",
    "    neutral_MNB_raw[\"f1-score\"].append(result[2][1])\n",
    "    negative_MNB_raw[\"f1-score\"].append(result[2][2])\n",
    "    \n",
    "    accuracy = accuracy_score(Y_test, prediction)\n",
    "    accuracies_MNB_raw.append(accuracy)    \n",
    "\n",
    "for key in positive_MNB_raw:\n",
    "    positive_MNB_raw[key] = np.mean(positive_MNB_raw[key])\n",
    "    negative_MNB_raw[key] = np.mean(negative_MNB_raw[key])\n",
    "    neutral_MNB_raw[key] = np.mean(neutral_MNB_raw[key])\n",
    "\n",
    "df_MNB_raw = pd.DataFrame([positive_MNB_raw, negative_MNB_raw, neutral_MNB_raw], index=[\"positive\", \"negative\", \"neutral\"])\n",
    "df_MNB_raw.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Having fitted 10 fold cross-validation, now we try the actual test\n",
    "X_train_raw = [x[0] for x in train_data[['text']].values]\n",
    "Y_train = [x[0] for x in train_data[['sentiment']].values]\n",
    "X_test_raw = [x[0] for x in test_data[['text']].values]\n",
    "\n",
    "train = preprocess(X_train_raw)\n",
    "train = tfidf_vectorizer.fit_transform(train)\n",
    "test = tfidf_vectorizer.transform(X_test_raw)\n",
    "\n",
    "mnb.fit(train, Y_train)\n",
    "prediction = mnb.predict(test)\n",
    "score1 = accuracy_score(Y_test, prediction)\n",
    "print(\"accuracy:   %0.3f\" % score1)\n",
    "\n",
    "print(classification_report(Y_test, prediction, target_names=['positive', 'negative', 'neutral']))\n",
    "\n",
    "print(\"confusion matrix:\")\n",
    "print(confusion_matrix(Y_test, prediction))\n",
    "# sentiments = pd.DataFrame({\n",
    "#   \"id\": [x[0] for x in test_data[['id']].values],\n",
    "#   \"sentiment\": prediction\n",
    "# })\n",
    "# sentiments.to_csv(\"MNB_sentiments.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive: re, white, right, tomorrow, one, kill, think, fuck, make, bad, people, say, do, go, like, get, it, trump, may, not\n",
      "neutral: one, know, trump, st, want, time, new, sunday, say, day, like, see, friday, it, get, tomorrow, go, th, may, not\n",
      "negative: sunday, great, watch, like, best, time, good, friday, get, night, not, it, may, th, love, happy, go, see, day, tomorrow\n",
      "positive: aa, moles, molly, molonlabe, molson, moly, moma, momentarily, moments, momma, mommy, moldy, mommynme, momthats, monaco, monastery, moncada, mondays, monet, monetary\n",
      "neutral: zwei, dough, douchebag, douche, doubts, mydumdass, myer, myfamilyweir, mymasterpiece, dote, mymotog, dose, dos, dork, dor, dopest, mypresident, doors, mypresidentisblack, myra\n",
      "negative: printable, recoup, guevara, sparking, guilt, sparen, guin, ocarina, ocampos, spare, guitarist, guiterriez, guji, gul, obvs, gullible, guesthouse, sparkle, guesstures, guessing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/utils/deprecation.py:103: FutureWarning: Attribute `coef_` was deprecated in version 0.24 and will be removed in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Print the n most informative words associated with each class\n",
    "\n",
    "def print_top_n(vectorizer, clf, class_labels, n):\n",
    "    \"\"\"Prints features with the highest coefficient values, per class\"\"\"\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    for i, class_label in enumerate(class_labels):\n",
    "        top10 = np.argsort(clf.coef_[i])[-n:]\n",
    "        print(\"%s: %s\" % (class_label,\n",
    "              \", \".join(feature_names[j] for j in top10)))\n",
    "\n",
    "def print_bot_n(vectorizer, clf, class_labels, n):\n",
    "    \"\"\"Prints features with the highest coefficient values, per class\"\"\"\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    for i, class_label in enumerate(class_labels):\n",
    "        top10 = np.argsort(clf.coef_[i])[:n]\n",
    "        print(\"%s: %s\" % (class_label,\n",
    "              \", \".join(feature_names[j] for j in top10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuning C for SVM for C from 0.01 to 100\n",
    "\n",
    "kf = KFold(n_splits=10)\n",
    "kf.get_n_splits(unbiased_dataset)\n",
    "\n",
    "accuracies_C_1 = []\n",
    "\n",
    "for c in [0.01, 0.1, 1, 10, 1000]:\n",
    "    train, test = train_test_split(unbiased_dataset, test_size=0.1, shuffle=False)\n",
    "    X_train = [x[0] for x in train[['text']].values]\n",
    "    Y_train = [x[0] for x in train[['sentiment']].values]\n",
    "    X_test = [x[0] for x in test[['text']].values]\n",
    "    Y_test = [x[0] for x in test[['sentiment']].values]\n",
    "    \n",
    "    # Preprocess the data\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    processed_data = preprocess(X_train)\n",
    "    processed_data_tf_idf = tfidf_vectorizer.fit_transform(processed_data)\n",
    "    processed_test_data_tf_idf = tfidf_vectorizer.transform(X_test)\n",
    "    \n",
    "    svm_model = svm.SVC(C=c,kernel='linear', degree=3, gamma='auto')\n",
    "    svm_model.fit(processed_data_tf_idf, Y_train)\n",
    "    prediction = svm_model.predict(processed_test_data_tf_idf)\n",
    "    accuracy = accuracy_score(Y_test, prediction)\n",
    "    accuracies_C_1.append(accuracy)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.XTick at 0x127ec39a0>,\n",
       "  <matplotlib.axis.XTick at 0x127ec3970>,\n",
       "  <matplotlib.axis.XTick at 0x127ec4f10>,\n",
       "  <matplotlib.axis.XTick at 0x12a6d5be0>,\n",
       "  <matplotlib.axis.XTick at 0x12a6d0370>],\n",
       " [Text(1, 0, '0.01'),\n",
       "  Text(2, 0, '0.1'),\n",
       "  Text(3, 0, '1'),\n",
       "  Text(4, 0, '10'),\n",
       "  Text(5, 0, '1000')])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(range(1, 6), accuracies_C_1)\n",
    "plt.xticks(range(1, 6))\n",
    "plt.xticks(range(1, 6), list(map(str, [0.01, 0.1, 1, 10, 1000])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5697674418604651, 0.5645994832041343, 0.5691214470284238, 0.5594315245478036, 0.5587855297157622, 0.5452196382428941, 0.5439276485788114, 0.5432816537467701, 0.5368217054263565, 0.5335917312661499]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAOaUlEQVR4nO3df6zdd13H8eeLlgoMAsiuBNuONtKgDcKAa5miE9lmOiEtETRdAhkGrCarDCHRombG+Q8/DOofjaFhg0UZZQyIV6kMAqjxD2bvxgS6UrnUwVqBXX4IKpFRePvH/XY53N32fLud873th+cjaXq+3/PJfX/usj3vud/zY6kqJEnnv0es9gYkSZNh0CWpEQZdkhph0CWpEQZdkhqxdrUGX3jhhbVp06bVGi9J56U77rjjq1U1s9J9qxb0TZs2MT8/v1rjJem8lOQLp7vPSy6S1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1IhVe6fow7Fp7wenPuOeN75o6jPO1g/r9y2pHx+hS1IjzstH6KvJR8mSzlUGXb34g0w69xl0nRem/QPFHyZqgdfQJakRBl2SGmHQJakRBl2SGuGTotIYq/mEbMuzx83X2fMRuiQ1wqBLUiO85CLpnOPlnofGoEvSiPP5h4mXXCSpEQZdkhph0CWpEQZdkhph0CWpEQZdkhph0CWpEQZdkhrRK+hJtic5mmQhyd4V7n9lksUkd3V/Xj35rUqSzmTsO0WTrAH2AVcAx4FDSeaq6u5lS99TVXumsEdJUg99HqFvAxaq6lhV3Q8cAHZOd1uSpLPVJ+jrgXtHjo9355Z7aZJPJbk1ycaVvlCS3Unmk8wvLi4+hO1Kkk5nUk+K/h2wqaqeCXwEuGmlRVW1v6pmq2p2ZmZmQqMlSdAv6CeA0UfcG7pzD6iqr1XVd7rDtwPPncz2JEl99Qn6IWBLks1J1gG7gLnRBUmeMnK4AzgyuS1KkvoY+yqXqjqZZA9wG7AGuLGqDie5HpivqjngNUl2ACeBrwOvnOKeJUkr6PU/uKiqg8DBZeeuG7n9BuANk92aJOls+E5RSWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWpEr6An2Z7kaJKFJHvPsO6lSSrJ7OS2KEnqY2zQk6wB9gFXAluBq5JsXWHd44BrgdsnvUlJ0nh9HqFvAxaq6lhV3Q8cAHausO5PgTcB/zfB/UmSeuoT9PXAvSPHx7tzD0jyHGBjVX3wTF8oye4k80nmFxcXz3qzkqTTe9hPiiZ5BPBW4PXj1lbV/qqararZmZmZhztakjSiT9BPABtHjjd05055HPAM4B+T3ANcAsz5xKgkDatP0A8BW5JsTrIO2AXMnbqzqr5ZVRdW1aaq2gR8AthRVfNT2bEkaUVjg15VJ4E9wG3AEeCWqjqc5PokO6a9QUlSP2v7LKqqg8DBZeeuO83aFzz8bUmSzpbvFJWkRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWpEr6An2Z7kaJKFJHtXuP+3k3w6yV1J/iXJ1slvVZJ0JmODnmQNsA+4EtgKXLVCsG+uqp+uqouBNwNvnfRGJUln1ucR+jZgoaqOVdX9wAFg5+iCqvrWyOEFQE1ui5KkPtb2WLMeuHfk+DjwvOWLklwDvA5YB7xwpS+UZDewG+Ciiy46271Kks5gYk+KVtW+qvoJ4PeBPzrNmv1VNVtVszMzM5MaLUmiX9BPABtHjjd0507nAPCSh7EnSdJD0Cfoh4AtSTYnWQfsAuZGFyTZMnL4IuBzk9uiJKmPsdfQq+pkkj3AbcAa4MaqOpzkemC+quaAPUkuB74LfAO4epqbliQ9WJ8nRamqg8DBZeeuG7l97YT3JUk6S75TVJIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIa0SvoSbYnOZpkIcneFe5/XZK7k3wqyUeTPHXyW5UkncnYoCdZA+wDrgS2Alcl2bps2SeB2ap6JnAr8OZJb1SSdGZ9HqFvAxaq6lhV3Q8cAHaOLqiqj1fVt7vDTwAbJrtNSdI4fYK+Hrh35Ph4d+50XgX8w0p3JNmdZD7J/OLiYv9dSpLGmuiTokleDswCb1np/qraX1WzVTU7MzMzydGS9ENvbY81J4CNI8cbunM/IMnlwB8Cv1hV35nM9iRJffV5hH4I2JJkc5J1wC5gbnRBkmcDbwN2VNV9k9+mJGmcsUGvqpPAHuA24AhwS1UdTnJ9kh3dsrcAjwXem+SuJHOn+XKSpCnpc8mFqjoIHFx27rqR25dPeF+SpLPkO0UlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqRG9gp5ke5KjSRaS7F3h/kuT3JnkZJKXTX6bkqRxxgY9yRpgH3AlsBW4KsnWZcu+CLwSuHnSG5Qk9bO2x5ptwEJVHQNIcgDYCdx9akFV3dPd9/0p7FGS1EOfSy7rgXtHjo93585akt1J5pPMLy4uPpQvIUk6jUGfFK2q/VU1W1WzMzMzQ46WpOb1CfoJYOPI8YbunCTpHNIn6IeALUk2J1kH7ALmprstSdLZGhv0qjoJ7AFuA44At1TV4STXJ9kBkORnkhwHfg14W5LD09y0JOnB+rzKhao6CBxcdu66kduHWLoUI0laJb5TVJIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqRG9gp5ke5KjSRaS7F3h/h9J8p7u/tuTbJr4TiVJZzQ26EnWAPuAK4GtwFVJti5b9irgG1X1NODPgTdNeqOSpDPr8wh9G7BQVceq6n7gALBz2ZqdwE3d7VuBy5JkctuUJI2TqjrzguRlwPaqenV3/ArgeVW1Z2TNZ7o1x7vjz3drvrrsa+0GdneHTweOTuob6eFC4KtjVznb2c529rk9+6lVNbPSHWsH3ARVtR/YP+TMU5LMV9Wss53tbGe3Mnu5PpdcTgAbR443dOdWXJNkLfB44GuT2KAkqZ8+QT8EbEmyOck6YBcwt2zNHHB1d/tlwMdq3LUcSdJEjb3kUlUnk+wBbgPWADdW1eEk1wPzVTUH3AD8dZIF4OssRf9csyqXepztbGc7eyhjnxSVJJ0ffKeoJDXCoEtSI5oPepIbk9zXvVZ+yLkbk3w8yd1JDie5dsDZj0ryr0n+rZv9J0PNHtnDmiSfTPL3qzD7niSfTnJXkvmBZz8hya1JPpvkSJKfHWju07vv99SfbyV57RCzu/m/2/279pkk707yqAFnX9vNPTzt73mlniT50SQfSfK57u8nTnMPZ9J80IF3AttXYe5J4PVVtRW4BLhmhY9MmJbvAC+sqmcBFwPbk1wy0OxTrgWODDxz1C9V1cWr8PrgvwQ+VFU/CTyLgf4ZVNXR7vu9GHgu8G3gA0PMTrIeeA0wW1XPYOnFE4O8MCLJM4DfZOkd7c8CXpzkaVMc+U4e3JO9wEeragvw0e54VTQf9Kr6Z5ZeeTP03C9V1Z3d7f9m6T/s9QPNrqr6n+7wkd2fwZ79TrIBeBHw9qFmnguSPB64lKVXfVFV91fVf63CVi4DPl9VXxhw5lrg0d37UB4D/OdAc38KuL2qvl1VJ4F/An51WsNO05PRjz65CXjJtOaP03zQzwXdp08+G7h9wJlrktwF3Ad8pKoGmw38BfB7wPcHnDmqgA8nuaP7uImhbAYWgXd0l5venuSCAeefsgt491DDquoE8GfAF4EvAd+sqg8PNP4zwC8keVKSxwC/wg++EXIIT66qL3W3vww8eeD5DzDoU5bkscD7gNdW1beGmltV3+t+/d4AbOt+NZ26JC8G7quqO4aYdxo/X1XPYekTQq9JculAc9cCzwH+qqqeDfwvA//63b35bwfw3gFnPpGlR6mbgR8HLkjy8iFmV9URlj7d9cPAh4C7gO8NMfs0+ykG/G14OYM+RUkeyVLM31VV71+NPXS/8n+c4Z5HeD6wI8k9LH0y5wuT/M1As4EHHjFSVfexdB1520CjjwPHR34bupWlwA/pSuDOqvrKgDMvB/6jqhar6rvA+4GfG2p4Vd1QVc+tqkuBbwD/PtTszleSPAWg+/u+gec/wKBPSffxwTcAR6rqrQPPnknyhO72o4ErgM8OMbuq3lBVG6pqE0u/+n+sqgZ5tAaQ5IIkjzt1G/hlln4tn7qq+jJwb5Knd6cuA+4eYvaIqxjwckvni8AlSR7T/Xt/GQM+IZ7kx7q/L2Lp+vnNQ83ujH70ydXA3w48/wGDftriakjybuAFwIVJjgN/XFU3DDD6+cArgE9317IB/qCqDg4w+ynATd3/nOQRwC1VNfjLB1fJk4EPdB/Hvxa4uao+NOD83wHe1V36OAb8xlCDux9gVwC/NdRMgKq6PcmtwJ0svbrrkwz7dvj3JXkS8F3gmmk+Eb1ST4A3ArckeRXwBeDXpzV/7P58678ktcFLLpLUCIMuSY0w6JLUCIMuSY0w6JLUCIMuSY0w6JLUiP8HmbjKkfeZ0zsAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tuning C for SVM for C from 1 to 10\n",
    "\n",
    "kf = KFold(n_splits=10)\n",
    "kf.get_n_splits(unbiased_dataset)\n",
    "\n",
    "accuracies_C_2 = []\n",
    "\n",
    "for c in range(1, 11):\n",
    "    train, test = train_test_split(unbiased_dataset, test_size=0.1, shuffle=False)\n",
    "    X_train = [x[0] for x in train[['text']].values]\n",
    "    Y_train = [x[0] for x in train[['sentiment']].values]\n",
    "    X_test = [x[0] for x in test[['text']].values]\n",
    "    Y_test = [x[0] for x in test[['sentiment']].values]\n",
    "    \n",
    "    # Preprocess the data\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    processed_data = preprocess(X_train)\n",
    "    processed_data_tf_idf = tfidf_vectorizer.fit_transform(processed_data)\n",
    "    processed_test_data_tf_idf = tfidf_vectorizer.transform(X_test)\n",
    "    \n",
    "    svm_model = svm.SVC(C=c,kernel='linear', degree=3, gamma='auto')\n",
    "    svm_model.fit(processed_data_tf_idf, Y_train)\n",
    "    prediction = svm_model.predict(processed_test_data_tf_idf)\n",
    "    accuracy = accuracy_score(Y_test, prediction)\n",
    "    accuracies_C_2.append(accuracy)  \n",
    "\n",
    "plt.bar(range(1, 11), accuracies_C_2)\n",
    "plt.xticks(range(1, 11))\n",
    "plt.xticks(range(1, 11), list(map(str, range(1, 11))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>0.704</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>0.609</td>\n",
       "      <td>0.476</td>\n",
       "      <td>0.533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neutral</th>\n",
       "      <td>0.519</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          precision  recall  f1-score\n",
       "Positive      0.704   0.499     0.583\n",
       "Negative      0.609   0.476     0.533\n",
       "Neutral       0.519   0.714     0.600"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform 10-fold cross-validation on SVM\n",
    "\n",
    "svm_model = svm.SVC(C=1.0,kernel='linear', degree=3, gamma='auto')\n",
    "\n",
    "kf = KFold(n_splits=10)\n",
    "kf.get_n_splits(unbiased_dataset)\n",
    "\n",
    "accuracies_SVM = []\n",
    "positive_SVM = defaultdict(list)\n",
    "negative_SVM = defaultdict(list)\n",
    "neutral_SVM = defaultdict(list)\n",
    "\n",
    "for train_index, test_index in kf.split(unbiased_dataset):\n",
    "    train = unbiased_dataset.iloc[train_index]\n",
    "    test = unbiased_dataset.iloc[test_index]\n",
    "    X_train = [x[0] for x in train[['text']].values]\n",
    "    Y_train = [x[0] for x in train[['sentiment']].values]\n",
    "    X_test = [x[0] for x in test[['text']].values]\n",
    "    Y_test = [x[0] for x in test[['sentiment']].values]\n",
    "    \n",
    "    # Preprocess the data\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    processed_data = preprocess(X_train)\n",
    "    processed_data_tf_idf = tfidf_vectorizer.fit_transform(processed_data)\n",
    "    processed_test_data_tf_idf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "    svm_model.fit(processed_data_tf_idf, Y_train)\n",
    "    prediction = svm_model.predict(processed_test_data_tf_idf)\n",
    "    result = precision_recall_fscore_support(Y_test, prediction, average=None, labels=['positive', 'neutral', 'negative'])\n",
    "    positive_SVM[\"precision\"].append(result[0][0])\n",
    "    neutral_SVM[\"precision\"].append(result[0][1])\n",
    "    negative_SVM[\"precision\"].append(result[0][2])\n",
    "    positive_SVM[\"recall\"].append(result[1][0])\n",
    "    neutral_SVM[\"recall\"].append(result[1][1])\n",
    "    negative_SVM[\"recall\"].append(result[1][2])\n",
    "    positive_SVM[\"f1-score\"].append(result[2][0])\n",
    "    neutral_SVM[\"f1-score\"].append(result[2][1])\n",
    "    negative_SVM[\"f1-score\"].append(result[2][2])\n",
    "    accuracy = accuracy_score(Y_test, prediction)\n",
    "    accuracies_SVM.append(accuracy)  \n",
    "\n",
    "for key in positive_SVM:\n",
    "    positive_SVM[key] = np.mean(positive_SVM[key])\n",
    "    negative_SVM[key] = np.mean(negative_SVM[key])\n",
    "    neutral_SVM[key] = np.mean(neutral_SVM[key])\n",
    "\n",
    "df_SVM = pd.DataFrame([positive_SVM, negative_SVM, neutral_SVM], index=[\"Positive\", \"Negative\", \"Neutral\"])\n",
    "df_SVM.round(3)[[\"precision\", \"recall\", \"f1-score\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>0.691</td>\n",
       "      <td>0.509</td>\n",
       "      <td>0.582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>0.610</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neutral</th>\n",
       "      <td>0.520</td>\n",
       "      <td>0.706</td>\n",
       "      <td>0.596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          precision  recall  f1-score\n",
       "Positive      0.691   0.509     0.582\n",
       "Negative      0.610   0.456     0.517\n",
       "Neutral       0.520   0.706     0.596"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_model = svm.SVC(C=1.0,kernel='linear', degree=3, gamma='auto')\n",
    "\n",
    "kf = KFold(n_splits=3)\n",
    "kf.get_n_splits(unbiased_dataset)\n",
    "\n",
    "accuracies_SVM_3 = []\n",
    "positive_SVM_3 = defaultdict(list)\n",
    "negative_SVM_3 = defaultdict(list)\n",
    "neutral_SVM_3 = defaultdict(list)\n",
    "\n",
    "for train_index, test_index in kf.split(unbiased_dataset):\n",
    "    train = unbiased_dataset.iloc[train_index]\n",
    "    test = unbiased_dataset.iloc[test_index]\n",
    "    X_train = [x[0] for x in train[['text']].values]\n",
    "    Y_train = [x[0] for x in train[['sentiment']].values]\n",
    "    X_test = [x[0] for x in test[['text']].values]\n",
    "    Y_test = [x[0] for x in test[['sentiment']].values]\n",
    "    \n",
    "    # Preprocess the data\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    processed_data = preprocess(X_train)\n",
    "    processed_data_tf_idf = tfidf_vectorizer.fit_transform(processed_data)\n",
    "    processed_test_data_tf_idf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "    svm_model.fit(processed_data_tf_idf, Y_train)\n",
    "    prediction = svm_model.predict(processed_test_data_tf_idf)\n",
    "    cfm = confusion_matrix(Y_test, prediction, labels=['positive', 'neutral', 'negative'])\n",
    "    result = precision_recall_fscore_support(Y_test, prediction, average=None, labels=['positive', 'neutral', 'negative'])\n",
    "    positive_SVM_3[\"accuracies\"].append(cfm[0][0] / sum(cfm[0]))\n",
    "    neutral_SVM_3[\"accuracies\"].append(cfm[1][1] / sum(cfm[1]))\n",
    "    negative_SVM_3[\"accuracies\"].append(cfm[2][2] / sum(cfm[2]))\n",
    "    positive_SVM_3[\"precision\"].append(result[0][0])\n",
    "    neutral_SVM_3[\"precision\"].append(result[0][1])\n",
    "    negative_SVM_3[\"precision\"].append(result[0][2])\n",
    "    positive_SVM_3[\"recall\"].append(result[1][0])\n",
    "    neutral_SVM_3[\"recall\"].append(result[1][1])\n",
    "    negative_SVM_3[\"recall\"].append(result[1][2])\n",
    "    positive_SVM_3[\"f1-score\"].append(result[2][0])\n",
    "    neutral_SVM_3[\"f1-score\"].append(result[2][1])\n",
    "    negative_SVM_3[\"f1-score\"].append(result[2][2])\n",
    "    accuracy = accuracy_score(Y_test, prediction)\n",
    "    accuracies_SVM_3.append(accuracy)  \n",
    "\n",
    "for key in positive_SVM_3:\n",
    "    positive_SVM_3[key] = np.mean(positive_SVM_3[key])\n",
    "    negative_SVM_3[key] = np.mean(negative_SVM_3[key])\n",
    "    neutral_SVM_3[key] = np.mean(neutral_SVM_3[key])\n",
    "\n",
    "df_SVM_3 = pd.DataFrame([positive_SVM_3, negative_SVM_3, neutral_SVM_3], index=[\"Positive\", \"Negative\", \"Neutral\"])\n",
    "df_SVM_3\n",
    "\n",
    "df_SVM_3.round(3)[[\"precision\", \"recall\", \"f1-score\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.7 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "X_train_raw = [x[0] for x in train_data[['text']].values]\n",
    "Y_train = [x[0] for x in train_data[['sentiment']].values]\n",
    "X_test_raw = [x[0] for x in test_data[['text']].values]\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "train = preprocess(X_train_raw)\n",
    "train = tfidf_vectorizer.fit_transform(train)\n",
    "test = tfidf_vectorizer.transform(X_test_raw)\n",
    "\n",
    "svm_model.fit(train, Y_train)\n",
    "predictions_SVM = svm_model.predict(test)\n",
    "\n",
    "sentiments = pd.DataFrame({\n",
    "  \"id\": [x[0] for x in test_data[['id']].values],\n",
    "  \"sentiment\": predictions_SVM\n",
    "})\n",
    "sentiments.to_csv(\"SVM_sentiments.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (main, Oct 13 2022, 10:17:43) [Clang 14.0.0 (clang-1400.0.29.102)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
